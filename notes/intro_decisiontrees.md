# intro ML classification


supervised learning

- KNN
- Decision trees -> random forest

output type is discrete (class labels)

looking for the decision boundary (boundary where A and B meet)

evaluation for accuracy of the algorithm

best practise: split data in training and test set 80-20%

want to have at least 50k datapoints


## kNN
don't want k too high (<50% of datapoints)
+ very intuitive
- slow when lots of data

## decision trees

decision trees can make multiple (linear) boundaries into 1 output
+ easy in interpret (graphically)
+ Oldest ML algorithm
+ extremely robust
- prone to overfitting

## other types of classification algorithms
- support vector machines
- naive bayes
- neural networks
